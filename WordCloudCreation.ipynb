{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import csv\n",
    "from os import path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "#Abrindo o corpus, e iterando ele.\n",
    "corpus = ''\n",
    "with open('Corpus.csv', 'r') as csvfile:\n",
    "    csv_file = csv.reader(csvfile)\n",
    "    for row in csv_file:\n",
    "        for line in row:\n",
    "            corpus += line.replace('\"',' ').replace(\"'\",\" \").lower() + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = ['muitos','onde','havia','dos','mas','dia','veio','disse','que','ficou','houve','era','uns','quem','qual','uns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrando o conteudo do corpus.\n",
    "corpus_tokenized = word_tokenize(corpus)\n",
    "#Criando a lista de stopwords com os stopwords do nltk, pontuações, e uma lista customizada com stopwords proprias.\n",
    "stop_words = set(stopwords.words('portuguese') + list(punctuation)+list(stopwords_list))\n",
    "corpus_tokenized_filtered = [token for token in corpus_tokenized if token not in stop_words and len(token)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando o contador de frequencia do nltk\n",
    "from nltk.probability import FreqDist\n",
    "top_tokens = FreqDist(corpus_tokenized_filtered)\n",
    "top_tokens = list(top_tokens.keys())\n",
    "top_100_tokens = top_tokens[:100]\n",
    "top_tokens_str = ''\n",
    "for word in top_100_tokens:\n",
    "    top_tokens_str += \" \"+word+\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guitar_mask = np.array(Image.open(\"semfundo.png\"))\n",
    "\n",
    "#Criando a wordcloud\n",
    "wc = WordCloud(background_color=\"white\", max_words=100, mask=guitar_mask,\n",
    "               contour_width=3, contour_color='firebrick')\n",
    "wc.generate(corpus_tokenized_filtered)\n",
    "plt.figure(figsize=[20,10])\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}